# üöÄ Transformers com Competi√ß√£o Estoc√°stica para Dados Tabulares

Os dados tabulares s√£o essenciais em diversos setores, mas ainda recebem pouca aten√ß√£o no deep learning, onde modelos como GBDT (Gradient Boosted Decision Trees) dominam. Por√©m, novas arquiteturas v√™m mudando esse cen√°rio, superando o GBDT em v√°rias situa√ß√µes. √â a√≠ que entra o modelo proposto nesse artigo: um Transformer estoc√°stico feito para dados tabulares, com:

- **Unidades Local Winner Takes All (LWTA):** Mais generaliza√ß√£o com estocasticidade e esparsidade.
- **Camada de Embedding com Competi√ß√£o Estoc√°stica:** Escolha din√¢mica entre embeddings lineares.

O modelo foi testado em bases p√∫blicas e teve resultados competitivos!

Caso tenham alguma d√∫vida pra executar esse script com a base de dados do projeto, podem consultar, principalmente, as duas fontes abaixo:

[Link para o artigo](https://arxiv.org/pdf/2407.13238)

[Link para o c√≥digo fonte original](https://github.com/avoskou/Transformers-with-Stochastic-Competition-for-Tabular-Data-Modelling)

**Nota dos pesquisadores:** O c√≥digo ainda est√° em vers√£o experimental.

### üìÇ Estrutura do Projeto
- **Model:** A pasta "STab" cont√©m todos os arquivos relacionados ao modelo.
- **train_tutorial:** Notebook Jupyter com exemplo de treinamento para o dataset "Iris". A estrutura segue praticamente a mesma com o novo dataset!


### üì¶ Depend√™ncias
Este projeto utiliza **torch** e **keras4torch** para treinamento e avalia√ß√£o, al√©m de componentes das seguintes implementa√ß√µes:
- [FtTransformer PyTorch](https://github.com/lucidrains/tab-transformer-pytorch)
- [Stochastic Transformer Networks](https://github.com/avoskou/Stochastic-Transformer-Networks-with-Linear-Competing-Units-Application-to-end-to-end-SL-Translatio)
- [Keras 4 Torch](https://github.com/blueloveTH/keras4torch)
